import os, asyncio
from typing import Dict, Any
from openai import OpenAI, BadRequestError

_CLIENT = None

def _client() -> OpenAI:
    global _CLIENT
    if _CLIENT is None:
        _CLIENT = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
    return _CLIENT

LLM_MINI = os.environ.get("LLM_MINI", "gpt-5-mini")
LLM_NANO = os.environ.get("LLM_NANO", "gpt-5-nano")
LLM_MAJOR = os.environ.get("LLM_MAJOR", "gpt-5")

async def _create_responses(model: str, prompt: str, max_out: int = 600) -> str:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –ø—É—Ç—å: Responses API.
    –ë–µ–∑ temperature –∏ max_tokens ‚Äî —Ç–æ–ª—å–∫–æ max_output_tokens (–∫–∞–∫ —Ç—Ä–µ–±—É–µ—Ç API).
    """
    cli = _client()
    try:
        resp = await asyncio.to_thread(
            cli.responses.create,
            model=model,
            input=prompt,
            max_output_tokens=max_out,
        )
        # —É –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ SDK —É –æ–±—ä–µ–∫—Ç–∞ –µ—Å—Ç—å —É–¥–æ–±–Ω–æ–µ —Å–≤–æ–π—Å—Ç–≤–æ
        out = getattr(resp, "output_text", None)
        if out is None:
            # –Ω–∞ –≤—Å—è–∫–∏–π ‚Äî —Å–æ–±–µ—Ä—ë–º –≤—Ä—É—á–Ω—É—é
            if resp.output and len(resp.output) and resp.output[0].content:
                out = "".join([b.text for b in (chunk.text for chunk in [resp.output[0].content]) if b])
        return out or ""
    except BadRequestError as e:
        # –ü–µ—Ä–µ–±—Ä–æ—Å–∏–º –Ω–∞—Ä—É–∂—É ‚Äî –≤–µ—Ä—Ö–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å –º–æ–∂–µ—Ç –¥–∞—Ç—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Ç–µ–∫—Å—Ç
        raise
    except Exception as e:
        raise

async def _fallback_chat(model: str, prompt: str, max_tokens: int = 600, temperature: float = 0.2) -> str:
    """
    –§–æ–ª–ª–±—ç–∫ –Ω–∞ chat.completions, –µ—Å–ª–∏ Responses —Ä—É–≥–Ω—É–ª—Å—è –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã/–º–æ–¥–µ–ª—å.
    """
    cli = _client()
    resp = await asyncio.to_thread(
        cli.chat.completions.create,
        model=model,
        messages=[{"role":"system","content":"–ö—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –Ω–∞ —Ä—É—Å—Å–∫–æ–º."},
                  {"role":"user","content":prompt}],
        temperature=temperature,
        max_tokens=max_tokens,
    )
    return (resp.choices[0].message.content or "").strip()

async def run_mini_digest(flags: Dict[str, Dict[str, Any]]) -> str:
    """
    flags: {"USDJPY":{"risk":"CAUTION","bias":"short-bias","notes":[...]}, ...}
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –ø–æ 4 –ø–∞—Ä–∞–º.
    """
    def _mk_line(sym: str, f: Dict[str, Any]) -> str:
        risk = f.get("risk","OK")
        bias = f.get("bias","both")
        notes = f.get("notes") or []
        bullet = "\n".join([f"‚Ä¢ {n}" for n in notes[:3]]) if notes else "‚Ä¢ –ë–µ–∑ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π."
        lbl = "‚úÖ –ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ" if risk=="OK" else ("‚ö†Ô∏è –û—Å—Ç–æ—Ä–æ–∂–Ω–æ" if risk=="CAUTION" else "üö® –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫")
        return f"{sym} ‚Äî {lbl}\n{bullet}\n–ß—Ç–æ –¥–µ–ª–∞–µ–º: —Ä–µ–∂–∏–º {bias}."
    text_blocks = [
        "üß≠ –£—Ç—Ä–µ–Ω–Ω–∏–π —Ñ–æ–Ω (–∫—Ä–∞—Ç–∫–æ)",
        _mk_line("USDJPY", flags.get("USDJPY", {})),
        _mk_line("AUDUSD", flags.get("AUDUSD", {})),
        _mk_line("EURUSD", flags.get("EURUSD", {})),
        _mk_line("GBPUSD", flags.get("GBPUSD", {})),
    ]
    prompt = "\n\n".join(text_blocks) + "\n\n–°—Ñ–æ—Ä–º–∏—Ä—É–π –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π, –∫–æ—Ä–æ—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –¥–ª—è —Ç—Ä–µ–π–¥-—á–∞—Ç–æ–≤."

    try:
        return await _create_responses(LLM_MINI, prompt, max_out=700)
    except BadRequestError as e:
        # –ß–∞—Å—Ç—ã–µ –∂–∞–ª–æ–±—ã: unsupported parameter (–µ—Å–ª–∏ SDK/—ç–Ω–¥–ø–æ–∏–Ω—Ç –Ω–µ —Å–æ–≤–ø–∞–ª–∏)
        # –ü—Ä–æ–±—É–µ–º —Ñ–æ–ª–ª–±—ç–∫ –Ω–∞ chat.completions
        try:
            return await _fallback_chat(LLM_MINI, prompt, max_tokens=700, temperature=0.2)
        except Exception as e2:
            raise RuntimeError(f"LLM (fallback) error: {e2}") from e
    except Exception as e:
        # –æ–±—â–∏–π —Ñ–æ–ª–ª–±—ç–∫ –Ω–∞ —á–∞—Ç
        try:
            return await _fallback_chat(LLM_MINI, prompt, max_tokens=700, temperature=0.2)
        except Exception as e2:
            raise RuntimeError(f"LLM error: {e2}") from e
